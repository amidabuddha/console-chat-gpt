# Make sure to rename this file to config.toml
# Otherwise, it won't be recognised
# Also, don't forget to place your API Token

# AUTOGENERATED SECTION - DO NOT EDIT
[chat.structure]
changelog_checksum = "dummy_value"

# Feel free to edit any value below this line
[chat.customizations]
use_emoji = true
fallback_char = "?"

[chat.defaults]
temperature = 1
system_role = "assistant"
model = "gemini-pro-exp"
assistant = "o4-mini"
assistant_role = "<instructions>\nInstructions for AI Assistant:\n\n- Select the optimal AI model to answer user questions based on their complexity and nature.\n- Provide your response only in JSON format, strictly following the example below.\n- The \"system\" message should contain clear, guiding instructions for the selected AI model, without sharing your reasoning or including your own answer or opinion.\n\n<example>\n{\n    \"model\": \"{{selected_model}}\",\n    \"messages\": [\n        {\"role\": \"system\", \"content\": \"{{system_instruction_to_ai_model}}\"}\n    ]\n}\n</example>\n\nEvaluation Criteria:\n\n1. Analyze the user's question based on topic, required depth of knowledge, and length.\n2. Select the most suitable model from the options, considering capabilities and cost-effectiveness.\n3. Use the tables below to guide your model selection.\n\n<table1>\n| Model Name     | Input Cost ($/1M tokens) | Output Cost ($/1M tokens) | Remarks                                                   |\n|----------------|--------------------------|---------------------------|-----------------------------------------------------------|\n| gpt-41 | 2.00                     | 8.00                     | High-intelligence model for complex, multi-step tasks.     |\n| gpt-41-mini   | 0.40                     | 1.60                      | Affordable, intelligent model for fast, lightweight tasks. |\n| o1             | 15.00                    | 60.00                     | Advanced reasoning model for solving hard problems across domains.   |\n| o4-mini        | 1.10                     | 4.40                     | Efficient reasoning in coding, math, and science.          |\n</table1>\n\nModels are ranked from highest to lowest capability. Only suggest the best-fitting model.\n\n<table2>\n| Category                               | Model to Consider  |\n|----------------------------------------|--------------------|\n| Math, Science, Coding                  | o4-mini            |\n| One-shot (deep reasoning with context) | o1                 |\n| Multi-turn, complex conversations with reasoning      | gpt-41     |\n| Complex tasks, problem solving across domains.                       | gpt-41     |\n| Common Tasks, General Topics           | gpt-41-mini       |\n</table2>\n\nNotes:\n\n- Do not include explanations or clarifications outside the JSON response.\n- Optimize query handling, model capability, and cost in your decision.\n</instructions>"

[chat.features]
model_selector = true
adjust_temperature = true
role_selector = true
save_chat_on_exit = true
continue_chat = true
debug = true
disable_intro_help_message = false
assistant_mode = true
ai_managed = true
streaming = false
mcp_client = true

[chat.roles]
ai_expert = "Simplify AI principles, Machine Learning, and Neural Networks for all understanding levels."
business_professional = "Propose focused strategies for market-driven sustainable business growth."
software_engineer = "Summarize best practices in coding for quality, optimization, and efficiency with applicable examples."
educator = "Customize advice for effective teaching and learning that caters to various styles."
fitness_coach = "Craft individualized fitness plans emphasizing balanced exercise, diet, and wellness."
healthcare_professional = "Provide health advice informed by the latest research, underlining smart health decision-making."
legal_professional = "Clarify legal issues and provide case-specific guidance for informed decision-making."
manager = "Share leadership insights to boost team efficiency, collaboration, and decision-making."
nutritionist = "Advise on nutrition blending science with practicality, focusing on proven, sustainable dietary habits."
scientist = "Make science engaging and understandable across math, physics, chemistry, and biology."
assistant = "Deliver precise and informative virtual assistance for any inquiry efficiently."

# ==================================
# OpenAI models
# ==================================
[chat.models.gpt-41-nano]
api_key = "YOUR_OPENAI_API_KEY"
base_url = ""
model_input_pricing_per_1k = 0.0001
model_max_tokens = 32768
model_name = "gpt-4.1-nano"
model_output_pricing_per_1k = 0.0004
reasoning_effort = false

[chat.models.gpt-41-mini]
api_key = "YOUR_OPENAI_API_KEY"
base_url = ""
model_input_pricing_per_1k = 0.0004
model_max_tokens = 32768
model_name = "gpt-4.1-mini"
model_output_pricing_per_1k = 0.0016
reasoning_effort = false

[chat.models.gpt-4o-mini]
api_key = "YOUR_OPENAI_API_KEY"
base_url = ""
model_input_pricing_per_1k = 0.00015
model_max_tokens = 16384
model_name = "gpt-4o-mini"
model_output_pricing_per_1k = 0.0006
reasoning_effort = false

[chat.models.gpt-4o]
api_key = "YOUR_OPENAI_API_KEY"
base_url = ""
model_input_pricing_per_1k = 0.0025
model_max_tokens = 16384
model_name = "gpt-4o"
model_output_pricing_per_1k = 0.01
reasoning_effort = false

[chat.models.gpt-4o-latest]
api_key = "YOUR_OPENAI_API_KEY"
base_url = ""
model_input_pricing_per_1k = 0.0025
model_max_tokens = 16384
model_name = "gpt-4o-2024-11-20"
model_output_pricing_per_1k = 0.01
reasoning_effort = false

[chat.models.gpt-4o-chatgpt]
api_key = "YOUR_OPENAI_API_KEY"
base_url = ""
model_input_pricing_per_1k = 0.005
model_max_tokens = 16384
model_name = "chatgpt-4o-latest"
model_output_pricing_per_1k = 0.015
reasoning_effort = false

[chat.models.gpt-41]
api_key = "YOUR_OPENAI_API_KEY"
base_url = ""
model_input_pricing_per_1k = 0.002
model_max_tokens = 32768
model_name = "gpt-4.1"
model_output_pricing_per_1k = 0.008
reasoning_effort = false

[chat.models.o1]
api_key = "YOUR_OPENAI_API_KEY"
model_input_pricing_per_1k = 0.015
model_max_tokens = 100000
model_name = "o1"
model_output_pricing_per_1k = 0.06
reasoning_effort = "medium"

[chat.models.o1-pro]
api_key = "YOUR_OPENAI_API_KEY"
model_input_pricing_per_1k = 0.15
model_max_tokens = 100000
model_name = "o1-pro"
model_output_pricing_per_1k = 0.6
reasoning_effort = "medium"

[chat.models.o3-mini]
api_key = "YOUR_OPENAI_API_KEY"
base_url = ""
model_input_pricing_per_1k = 0.0011
model_max_tokens = 100000
model_name = "o3-mini"
model_output_pricing_per_1k = 0.0044
reasoning_effort = "medium"

[chat.models.o3]
api_key = "YOUR_OPENAI_API_KEY"
base_url = ""
model_input_pricing_per_1k = 0.01
model_max_tokens = 100000
model_name = "o3"
model_output_pricing_per_1k = 0.04
reasoning_effort = "medium"

[chat.models.o4-mini]
api_key = "YOUR_OPENAI_API_KEY"
base_url = ""
model_input_pricing_per_1k = 0.0011
model_max_tokens = 100000
model_name = "o4-mini"
model_output_pricing_per_1k = 0.0044
reasoning_effort = "medium"

# ==================================
# Mistral models
# ==================================
[chat.models.mistral-saba]
api_key = "YOUR_MISTRALAI_API_KEY"
base_url = ""
model_input_pricing_per_1k = 0.0002
model_max_tokens = 32000
model_name = "mistral-saba-latest"
model_output_pricing_per_1k = 0.0006
reasoning_effort = false

[chat.models.mistral-medium]
api_key = "YOUR_MISTRALAI_API_KEY"
base_url = ""
model_input_pricing_per_1k = 0.0004
model_max_tokens = 128000
model_name = "mistral-medium-latest"
model_output_pricing_per_1k = 0.002
reasoning_effort = false

[chat.models.mistral-large]
api_key = "YOUR_MISTRALAI_API_KEY"
base_url = ""
model_input_pricing_per_1k = 0.002
model_max_tokens = 128000
model_name = "mistral-large-latest"
model_output_pricing_per_1k = 0.006
reasoning_effort = false

[chat.models.mistral-codestral]
api_key = "YOUR_MISTRALAI_API_KEY"
base_url = ""
model_input_pricing_per_1k = 0.0003
model_max_tokens = 256000
model_name = "codestral-latest"
model_output_pricing_per_1k = 0.0009
reasoning_effort = false

[chat.models.pixtral-large]
api_key = "YOUR_MISTRALAI_API_KEY"
base_url = ""
model_input_pricing_per_1k = 0.002
model_max_tokens = 128000
model_name = "pixtral-large-latest"
model_output_pricing_per_1k = 0.006
reasoning_effort = false

# ==================================
# Anthropic models
# ==================================
[chat.models.anthropic-haiku]
api_key = "YOUR_ANTHROPIC_API_KEY"
base_url = ""
model_input_pricing_per_1k = 0.0008
model_max_tokens = 8192
model_name = "claude-3-5-haiku-latest"
model_output_pricing_per_1k = 0.004
reasoning_effort = false

[chat.models.anthropic-sonnet-3-legacy]
api_key = "YOUR_ANTHROPIC_API_KEY"
base_url = ""
model_input_pricing_per_1k = 0.003
model_max_tokens = 8192
model_name = "claude-3-5-sonnet-latest"
model_output_pricing_per_1k = 0.015
reasoning_effort = false

[chat.models.anthropic-sonnet-3]
api_key = "YOUR_ANTHROPIC_API_KEY"
base_url = ""
model_input_pricing_per_1k = 0.003
model_max_tokens = 64000
model_name = "claude-3-7-sonnet-latest"
model_output_pricing_per_1k = 0.015
reasoning_effort = "medium"

[chat.models.anthropic-sonnet-4]
api_key = "YOUR_ANTHROPIC_API_KEY"
base_url = ""
model_input_pricing_per_1k = 0.003
model_max_tokens = 64000
model_name = "claude-sonnet-4-0"
model_output_pricing_per_1k = 0.015
reasoning_effort = "medium"

[chat.models.anthropic-opus-4]
api_key = "YOUR_ANTHROPIC_API_KEY"
base_url = ""
model_input_pricing_per_1k = 0.015
model_max_tokens = 32000
model_name = "claude-opus-4-0"
model_output_pricing_per_1k = 0.075
reasoning_effort = "medium"

# ==================================
# xAI models
# ==================================
[chat.models.grok-3]
api_key = "YOUR_GROK_API_KEY"
base_url = "https://api.x.ai/v1"
model_input_pricing_per_1k = 0.003
model_max_tokens = 131072
model_name = "grok-3-latest"
model_output_pricing_per_1k = 0.015
reasoning_effort = false

[chat.models.grok-3-fast]
api_key = "YOUR_GROK_API_KEY"
base_url = "https://api.x.ai/v1"
model_input_pricing_per_1k = 0.005
model_max_tokens = 131072
model_name = "grok-3-fast-latest"
model_output_pricing_per_1k = 0.025
reasoning_effort = false

[chat.models.grok-3-mini]
api_key = "YOUR_GROK_API_KEY"
base_url = "https://api.x.ai/v1"
model_input_pricing_per_1k = 0.0003
model_max_tokens = 131072
model_name = "grok-3-mini-latest"
model_output_pricing_per_1k = 0.0005
reasoning_effort = "medium"

[chat.models.grok-3-mini-fast]
api_key = "YOUR_GROK_API_KEY"
base_url = "https://api.x.ai/v1"
model_input_pricing_per_1k = 0.0006
model_max_tokens = 131072
model_name = "grok-3-mini-fast-latest"
model_output_pricing_per_1k = 0.004
reasoning_effort = "medium"

[chat.models.grok-2-vision]
api_key = "YOUR_GROK_API_KEY"
base_url = "https://api.x.ai/v1"
model_input_pricing_per_1k = 0.002
model_max_tokens = 32768
model_name = "grok-2-vision-latest"
model_output_pricing_per_1k = 0.01
reasoning_effort = false

# ==================================
# Google models
# ==================================
[chat.models.gemini-flash]
api_key = "YOUR_GEMINI_API_KEY"
base_url = "https://generativelanguage.googleapis.com/v1beta/openai/"
model_input_pricing_per_1k = 0.00015
model_max_tokens = 65536
model_name = "gemini-2.5-flash-preview-05-20"
model_output_pricing_per_1k = 0.0006
reasoning_effort = "medium"

[chat.models.gemini-pro]
api_key = "YOUR_GEMINI_API_KEY"
base_url = "https://generativelanguage.googleapis.com/v1beta/openai/"
model_input_pricing_per_1k = 0.00125
model_max_tokens = 8192
model_name = "gemini-2.5-pro-preview-06-05"
model_output_pricing_per_1k = 0.01
reasoning_effort = "medium"

# ==================================
# DeepSeek models
# ==================================
[chat.models.deepseek-chat]
api_key = "YOUR_DEEPSEEK_API_KEY"
base_url = "https://api.deepseek.com/v1"
model_input_pricing_per_1k = 0.00027
model_max_tokens = 8192
model_name = "deepseek-chat"
model_output_pricing_per_1k = 0.0011
reasoning_effort = false

[chat.models.deepseek-reasoner]
api_key = "YOUR_DEEPSEEK_API_KEY"
base_url = "https://api.deepseek.com/v1"
model_input_pricing_per_1k = 0.00055
model_max_tokens = 8192
model_name = "deepseek-reasoner"
model_output_pricing_per_1k = 0.00219
reasoning_effort = false

# ==================================
# Alibaba Cloud models
# ==================================
[chat.models.qwen-turbo]
api_key = "YOUR_ALIBABA_API_KEY"
base_url = "https://dashscope-intl.aliyuncs.com/compatible-mode/v1"
model_input_pricing_per_1k = 0.00005
model_max_tokens = 8192
model_name = "qwen-turbo-latest"
model_output_pricing_per_1k = 0.0002
reasoning_effort = false

[chat.models.qwen-plus]
api_key = "YOUR_ALIBABA_API_KEY"
base_url = "https://dashscope-intl.aliyuncs.com/compatible-mode/v1"
model_input_pricing_per_1k = 0.0004
model_max_tokens = 8192
model_name = "qwen-plus-latest"
model_output_pricing_per_1k = 0.0012
reasoning_effort = false

[chat.models.qwen-max]
api_key = "YOUR_ALIBABA_API_KEY"
base_url = "https://dashscope-intl.aliyuncs.com/compatible-mode/v1"
model_input_pricing_per_1k = 0.0016
model_max_tokens = 8192
model_name = "qwen-max-latest"
model_output_pricing_per_1k = 0.0064
reasoning_effort = false

[chat.models.qwq-plus]
api_key = "YOUR_ALIBABA_API_KEY"
base_url = "https://dashscope-intl.aliyuncs.com/compatible-mode/v1"
model_input_pricing_per_1k = 0.0008
model_max_tokens = 8192
model_name = "qwq-plus"
model_output_pricing_per_1k = 0.0024
reasoning_effort = false

[chat.models.qvq-max]
api_key = "YOUR_ALIBABA_API_KEY"
base_url = "https://dashscope-intl.aliyuncs.com/compatible-mode/v1"
model_input_pricing_per_1k = 0.00
model_max_tokens = 8192
model_name = "qvq-max"
model_output_pricing_per_1k = 0.00
reasoning_effort = false

[chat.models.qwen-vl-max]
api_key = "YOUR_ALIBABA_API_KEY"
base_url = "https://dashscope-intl.aliyuncs.com/compatible-mode/v1"
model_input_pricing_per_1k = 0.0008
model_max_tokens = 2048
model_name = "qwen-vl-max"
model_output_pricing_per_1k = 0.0032
reasoning_effort = false

[chat.models.qwen-vl-plus]
api_key = "YOUR_ALIBABA_API_KEY"
base_url = "https://dashscope-intl.aliyuncs.com/compatible-mode/v1"
model_input_pricing_per_1k = 0.00021
model_max_tokens = 2048
model_name = "qwen-vl-plus"
model_output_pricing_per_1k = 0.00063
reasoning_effort = false

# ==================================
# Inception Lab models
# ==================================
[chat.models.mercury-coder-small]
api_key = "YOUR_MERCURY_API_KEY"
base_url = "https://api.inceptionlabs.ai/v1"
model_input_pricing_per_1k = 0.00
model_max_tokens = 32000
model_name = "mercury-coder-small"
model_output_pricing_per_1k = 0.00
reasoning_effort = false