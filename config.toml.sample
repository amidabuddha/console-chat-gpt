# Make sure to rename this file to config.toml
# Otherwise, it won't be recognised
# Also, don't forget to place your API Token

# AUTOGENERATED SECTION - DO NOT EDIT
[chat.structure]
changelog_checksum = "dummy_value"

# Feel free to edit any value below this line
[chat.customizations]
use_emoji = true
fallback_char = "?"

[chat.defaults]
temperature = 1
system_role = "assistant"
model = "gpt-5"

[chat.managed]
assistant = "gpt-5-mini"
assistant_role = "<instructions>\nInstructions for AI Assistant:\n\n- Select the optimal AI model to answer user questions based on their complexity and nature.\n- Provide your response only in JSON format, strictly following the example below.\n- The \"system\" message should contain clear, guiding instructions for the selected AI model, without sharing your reasoning or including your own answer or opinion.\n\n<example>\n{\n    \"model\": \"{{selected_model}}\",\n    \"messages\": [\n        {\"role\": \"system\", \"content\": \"{{system_instruction_to_ai_model}}\"}\n    ]\n}\n</example>\n\nEvaluation Criteria:\n\n1. Analyze the user's question based on topic, required depth of knowledge, and length.\n2. Select the most suitable model from the options, considering capabilities and cost-effectiveness.\n3. Use the tables below to guide your model selection.\n\n<table1>\n| Model Name | Cost | Remarks |\n|-|-|-|-|\n| {{assistant_generalist}} | Highest | High-intelligence model for complex, multi-step tasks. |\n| {{assistant_fast}} | Cheapest | Affordable, intelligent model for fast, lightweight tasks. |\n| {{assistant_thinker}} | Highest | Advanced reasoning model for solving hard problems across domains. |\n| {{assistant_coder}} | Medium | Efficient reasoning in coding, math, and science. |\n</table1>\n\nModels are ranked from highest to lowest capability. Only suggest the best-fitting model.\n\n<table2>\n| Category | Model to Consider |\n|-|-|\n| Math, Science, Coding | {{assistant_coder}} |\n| One-shot (deep reasoning with context) | {{assistant_thinker}} |\n| Multi-turn, complex conversations with reasoning | {{assistant_generalist}} |\n| Complex tasks, problem solving across domains. | {{assistant_generalist}} |\n| Common Tasks, General Topics | {{assistant_fast}} |\n</table2>\n\nNotes:\n\n- Do not include explanations or clarifications outside the JSON response.\n- Optimize query handling, model capability, and cost in your decision.\n</instructions>"
assistant_generalist = "gpt-5-chat"
assistant_fast = "gpt-5-mini"
assistant_thinker = "gpt-5"
assistant_coder = "gpt-5"
prompt = true

[chat.features]
model_selector = true
adjust_temperature = true
role_selector = true
save_chat_on_exit = true
continue_chat = true
debug = true
disable_intro_help_message = false
assistant_mode = true
ai_managed = true
streaming = false
mcp_client = true

[chat.roles]
ai_expert = "Simplify AI principles, Machine Learning, and Neural Networks for all understanding levels."
business_professional = "Propose focused strategies for market-driven sustainable business growth."
software_engineer = "Summarize best practices in coding for quality, optimization, and efficiency with applicable examples."
educator = "Customize advice for effective teaching and learning that caters to various styles."
fitness_coach = "Craft individualized fitness plans emphasizing balanced exercise, diet, and wellness."
healthcare_professional = "Provide health advice informed by the latest research, underlining smart health decision-making."
legal_professional = "Clarify legal issues and provide case-specific guidance for informed decision-making."
manager = "Share leadership insights to boost team efficiency, collaboration, and decision-making."
nutritionist = "Advise on nutrition blending science with practicality, focusing on proven, sustainable dietary habits."
scientist = "Make science engaging and understandable across math, physics, chemistry, and biology."
assistant = "Deliver precise and informative virtual assistance for any inquiry efficiently."

# ==================================
# OpenAI models
# ==================================
[chat.models.gpt-41-nano]
api_key = "YOUR_API_KEY"
base_url = ""
model_input_pricing_per_1k = 0.0001
model_max_tokens = 1047576
model_name = "gpt-4.1-nano"
model_output_pricing_per_1k = 0.0004
reasoning_effort = false
verbosity = false

[chat.models.gpt-41-mini]
api_key = "YOUR_API_KEY"
base_url = ""
model_input_pricing_per_1k = 0.0004
model_max_tokens = 1047576
model_name = "gpt-4.1-mini"
model_output_pricing_per_1k = 0.0016
reasoning_effort = false
verbosity = false

[chat.models.gpt-41]
api_key = "YOUR_API_KEY"
base_url = ""
model_input_pricing_per_1k = 0.002
model_max_tokens = 1047576
model_name = "gpt-4.1"
model_output_pricing_per_1k = 0.008
reasoning_effort = false
verbosity = false

[chat.models.o3-pro]
api_key = "YOUR_API_KEY"
base_url = ""
model_input_pricing_per_1k = 0.02
model_max_tokens = 200000
model_name = "o3-pro"
model_output_pricing_per_1k = 0.08
reasoning_effort = "medium"
verbosity = false

[chat.models.gpt-5-nano]
api_key = "YOUR_API_KEY"
base_url = ""
model_input_pricing_per_1k = 0.00005
model_max_tokens = 400000
model_name = "gpt-5-nano"
model_output_pricing_per_1k = 0.0004
reasoning_effort = "medium"
verbosity = "low"

[chat.models.gpt-5-mini]
api_key = "YOUR_API_KEY"
base_url = ""
model_input_pricing_per_1k = 0.00025
model_max_tokens = 400000
model_name = "gpt-5-mini"
model_output_pricing_per_1k = 0.002
reasoning_effort = "medium"
verbosity = "low"

[chat.models.gpt-5]
api_key = "YOUR_API_KEY"
base_url = ""
model_input_pricing_per_1k = 0.00125
model_max_tokens = 400000
model_name = "gpt-5"
model_output_pricing_per_1k = 0.01
reasoning_effort = "medium"
verbosity = "low"

[chat.models.gpt-5-codex]
api_key = "YOUR_API_KEY"
base_url = ""
model_input_pricing_per_1k = 0.00125
model_max_tokens = 400000
model_name = "gpt-5-codex"
model_output_pricing_per_1k = 0.01
reasoning_effort = "medium"
verbosity = "low"

# ==================================
# Mistral models
# ==================================
[chat.models.mistral-small]
api_key = "YOUR_API_KEY"
base_url = ""
model_input_pricing_per_1k = 0.0002
model_max_tokens = 128000
model_name = "mistral-small-latest"
model_output_pricing_per_1k = 0.0006
reasoning_effort = false

[chat.models.mistral-medium]
api_key = "YOUR_API_KEY"
base_url = ""
model_input_pricing_per_1k = 0.0004
model_max_tokens = 128000
model_name = "mistral-medium-latest"
model_output_pricing_per_1k = 0.002
reasoning_effort = false

[chat.models.mistral-large]
api_key = "YOUR_API_KEY"
base_url = ""
model_input_pricing_per_1k = 0.002
model_max_tokens = 128000
model_name = "mistral-large-latest"
model_output_pricing_per_1k = 0.006
reasoning_effort = false

[chat.models.mistral-codestral]
api_key = "YOUR_API_KEY"
base_url = ""
model_input_pricing_per_1k = 0.0003
model_max_tokens = 256000
model_name = "codestral-latest"
model_output_pricing_per_1k = 0.0009
reasoning_effort = false

[chat.models.pixtral-large]
api_key = "YOUR_API_KEY"
base_url = ""
model_input_pricing_per_1k = 0.002
model_max_tokens = 128000
model_name = "pixtral-large-latest"
model_output_pricing_per_1k = 0.006
reasoning_effort = false

[chat.models.magistral-medium]
api_key = "YOUR_API_KEY"
base_url = ""
model_input_pricing_per_1k = 0.002
model_max_tokens = 40000
model_name = "magistral-medium-latest"
model_output_pricing_per_1k = 0.005
reasoning_effort = false

# ==================================
# Anthropic models
# ==================================
[chat.models.anthropic-haiku]
api_key = "YOUR_API_KEY"
base_url = ""
model_input_pricing_per_1k = 0.0008
model_max_tokens = 8192
model_name = "claude-3-5-haiku-latest"
model_output_pricing_per_1k = 0.004
reasoning_effort = false

[chat.models.anthropic-sonnet-3-legacy]
api_key = "YOUR_API_KEY"
base_url = ""
model_input_pricing_per_1k = 0.003
model_max_tokens = 8192
model_name = "claude-3-5-sonnet-latest"
model_output_pricing_per_1k = 0.015
reasoning_effort = false

[chat.models.anthropic-sonnet-3]
api_key = "YOUR_API_KEY"
base_url = ""
model_input_pricing_per_1k = 0.003
model_max_tokens = 64000
model_name = "claude-3-7-sonnet-latest"
model_output_pricing_per_1k = 0.015
reasoning_effort = "medium"

[chat.models.anthropic-sonnet-4]
api_key = "YOUR_API_KEY"
base_url = ""
model_input_pricing_per_1k = 0.003
model_max_tokens = 64000
model_name = "claude-sonnet-4-0"
model_output_pricing_per_1k = 0.015
reasoning_effort = "medium"

[chat.models.anthropic-opus-4-0]
api_key = "YOUR_API_KEY"
base_url = ""
model_input_pricing_per_1k = 0.015
model_max_tokens = 32000
model_name = "claude-opus-4-0"
model_output_pricing_per_1k = 0.075
reasoning_effort = "medium"

[chat.models.anthropic-opus-4-1]
api_key = "YOUR_API_KEY"
base_url = ""
model_input_pricing_per_1k = 0.015
model_max_tokens = 32000
model_name = "claude-opus-4-1"
model_output_pricing_per_1k = 0.075
reasoning_effort = "medium"

# ==================================
# xAI models
# ==================================
[chat.models.grok-code-fast]
api_key = "YOUR_API_KEY"
base_url = "https://api.x.ai/v1"
model_input_pricing_per_1k = 0.0002
model_max_tokens = 256000
model_name = "grok-code-fast"
model_output_pricing_per_1k = 0.0015
reasoning_effort = false

[chat.models.grok-4]
api_key = "YOUR_API_KEY"
base_url = "https://api.x.ai/v1"
model_input_pricing_per_1k = 0.003
model_max_tokens = 256000
model_name = "grok-4-latest"
model_output_pricing_per_1k = 0.015
reasoning_effort = false

[chat.models.grok-4-fast]
api_key = "YOUR_API_KEY"
base_url = "https://api.x.ai/v1"
model_input_pricing_per_1k = 0.0002
model_max_tokens = 2000000
model_name = "grok-4-fast-reasoning-latest"
model_output_pricing_per_1k = 0.0005
reasoning_effort = false

[chat.models.grok-4-fast-non-reasoning]
api_key = "YOUR_API_KEY"
base_url = "https://api.x.ai/v1"
model_input_pricing_per_1k = 0.0002
model_max_tokens = 2000000
model_name = "grok-4-fast-non-reasoning-latest"
model_output_pricing_per_1k = 0.0005
reasoning_effort = false

# ==================================
# Google models
# ==================================
[chat.models.gemini-flash]
api_key = "YOUR_API_KEY"
base_url = "https://generativelanguage.googleapis.com/v1beta/openai/"
model_input_pricing_per_1k = 0.0003
model_max_tokens = 1048576
model_name = "gemini-2.5-flash"
model_output_pricing_per_1k = 0.0025
reasoning_effort = "medium"

[chat.models.gemini-pro]
api_key = "YOUR_API_KEY"
base_url = "https://generativelanguage.googleapis.com/v1beta/openai/"
model_input_pricing_per_1k = 0.00125
model_max_tokens = 1048576
model_name = "gemini-2.5-pro"
model_output_pricing_per_1k = 0.01
reasoning_effort = "medium"